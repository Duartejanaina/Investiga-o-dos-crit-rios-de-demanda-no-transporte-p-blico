{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para tratamento dos dados para OD por geolocalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento dos arquivos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Arquivo bilhetagem\n",
    "sbe_caminho = r\"G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_ADAPTACAOBOTELHO\\Dezembro_2023\\20231206\\exputiliz_2023-12-06.csv\"\n",
    "sbe = pd.read_csv(sbe_caminho, sep=\";\", encoding=\"latin1\", dtype={'CODIGO_VEICULO': 'object', 'CODIGO_LINHA': 'object'}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe['DATAHORA_UTILIZACAO'] = pd.to_datetime(sbe['DATAHORA_UTILIZACAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe['DATAHORA_UTILIZACAO'] = pd.to_datetime(sbe['DATAHORA_UTILIZACAO'])\n",
    "sbe['HORARIO'] = sbe['DATAHORA_UTILIZACAO'].dt.strftime('%H:%M:%S')\n",
    "sbe['DATA'] = sbe['DATAHORA_UTILIZACAO'].dt.strftime('%Y-%m-%d')\n",
    "sbe['HORARIO'] = pd.to_datetime(sbe['HORARIO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbe[sbe['DATA'] == \"2023-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos = sbe['CODIGO_VEICULO'].unique()\n",
    "valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe= sbe[\n",
    "    ~(\n",
    "        (sbe['TIPO_CARTAO'] == 'UNITÁRIO BRT') |(sbe['TIPO_CARTAO'] == 'CARTAO VIRTUAL')| (sbe['TIPO_CARTAO'] == 'OPERACIONAL BHTRANS') | (sbe['TIPO_CARTAO'] == 'ADMINISTRATIVO') | (sbe['TIPO_CARTAO'] == 'ACESSO TECNICO E OPERACIONAL') | (sbe['TIPO_CARTAO'] == 'GRATUIDADE SEM CARTAO') | (sbe['TIPO_CARTAO'] == 'AUXILIAR DE OPERAÇÕES')| (sbe['TIPO_CARTAO'] == 'RODOVIÁRIO METROPOLITANO'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associando o gps PING com o sbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando múltiplos filtros em uma única operação\n",
    "sbe_ping = sbe[\n",
    "    ~(\n",
    "        (sbe['NOME_OPERADORA'] == 'METRÔ BH') |\n",
    "        (sbe['NOME_OPERADORA'] == 'CBTU') |\n",
    "        sbe['NOME_OPERADORA'].str.startswith('ESTAÇÃO') |\n",
    "        (sbe['NOME_OPERADORA'] == 'SINDPAUTRAS') |\n",
    "        (sbe['CODIGO_LINHA'].str.startswith(\"AC\")) |\n",
    "        (sbe['CODIGO_LINHA'].str.startswith('CM')) |\n",
    "        (sbe['CODIGO_LINHA'].str.startswith('PR')) |\n",
    "        (sbe['CODIGO_LINHA'].str.startswith('SD')) |\n",
    "        (sbe['CODIGO_VEICULO'].str.startswith('UC')) |\n",
    "        (sbe['CODIGO_VEICULO'].str.startswith('UE'))\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbe_ping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_linha(linha):\n",
    "    # Remove caracteres indesejados e separa com base em ';'\n",
    "    partes = linha.strip('<>;\\n').split(';')\n",
    "    # Cria um dicionário a partir dos valores separados\n",
    "    return {parte.split('=')[0]: parte.split('=')[1] for parte in partes if parte}\n",
    "\n",
    "diretorio_atual = os.getcwd()\n",
    "caminho_pasta = os.path.join(diretorio_atual, \"PING\")\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "dfs = []\n",
    "\n",
    "for arquivo in os.listdir(caminho_pasta):\n",
    "    if arquivo.endswith(\".csv\"):\n",
    "        caminho_completo = os.path.join(caminho_pasta, arquivo)\n",
    "        with open(caminho_completo, 'r', encoding='latin-1') as f:\n",
    "            linhas = f.readlines()[1:]  # Pula o cabeçalho\n",
    "            dados = [processar_linha(linha) for linha in linhas]\n",
    "            df = pd.DataFrame(dados)\n",
    "            dfs.append(df)\n",
    "\n",
    "gps = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = gps.drop_duplicates().reset_index(drop=True)\n",
    "gps[\"geometry\"] = gps.apply(lambda row: Point(row[\"LG\"], row[\"LT\"]), axis=1)\n",
    "\n",
    "gps_gdf = gpd.GeoDataFrame(gps, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "# gps_gdf = gps_gdf.to_crs(\"EPSG:31983\")\n",
    "gps_gdf[\"HR\"] = pd.to_datetime(gps_gdf[\"HR\"], format=\"%Y%m%d%H%M%S\")\n",
    "gps_gdf = gps_gdf.sort_values(by=[\"HR\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_gdf.rename(columns={\"HR\": \"DH\", \"NV\": \"CODIGO_VEICULO\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_gdf['DH'] = pd.to_datetime(gps_gdf['DH'])\n",
    "gps_gdf['HORARIO_GPS'] = gps_gdf['DH'].dt.strftime('%H:%M:%S')\n",
    "gps_gdf['DATA_GPS'] = gps_gdf['DH'].dt.strftime('%Y-%m-%d')\n",
    "gps_gdf = gps_gdf.dropna().reset_index(drop=True)\n",
    "\n",
    "gps_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_gdf[\"CODIGO_VEICULO\"]= gps_gdf[\"CODIGO_VEICULO\"].astype(\"int64\")\n",
    "sbe_ping[\"CODIGO_VEICULO\"]= sbe_ping[\"CODIGO_VEICULO\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convertendo as colunas de horário para datetime, se ainda não estiverem\n",
    "gps_gdf['HORARIO_GPS'] = pd.to_datetime(gps_gdf['HORARIO_GPS'])\n",
    "sbe_ping['HORARIO'] = pd.to_datetime(sbe_ping['HORARIO'])\n",
    "\n",
    "\n",
    "\n",
    "# Fazendo o merge usando merge_asof para encontrar as linhas correspondentes em gps_gdf\n",
    "merged = pd.merge_asof(sbe_ping.sort_values('HORARIO'),\n",
    "                       gps_gdf.sort_values('HORARIO_GPS'),\n",
    "                       left_on='HORARIO',\n",
    "                       right_on='HORARIO_GPS',\n",
    "                       by='CODIGO_VEICULO',\n",
    "                       direction='backward',\n",
    "                       tolerance=pd.Timedelta(seconds=40))\n",
    "\n",
    "\n",
    "# Resultado contém as geometrias do gps_gdf correspondentes ao horário mais próximo anterior em sbe_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associando o metrô com a localização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando as linhas com NOME_OPERADORA igual a 'METRÔ BH'\n",
    "sbe_metro = sbe[(sbe['NOME_OPERADORA'] == 'METRÔ BH') | (sbe['NOME_OPERADORA'] == 'CBTU')]\n",
    "\n",
    "\n",
    "\n",
    "sbe_metro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_geo_metro_caminho = r\"G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_HEXAGONO\\ESTACAO_METRO.csv\"\n",
    "gps_metro = pd.read_csv(gps_geo_metro_caminho, sep= \";\", encoding= \"latin1\")\n",
    "gps_metro = gps_metro.rename(columns={'CODIGO': 'CODIGO_VEICULO'})\n",
    "# Converta a coluna 'CODIGO_LINHA' para string em ambos os DataFrames\n",
    "sbe_metro['CODIGO_LINHA'] = sbe_metro['CODIGO_LINHA'].astype(str)\n",
    "gps_metro['CODIGO_LINHA'] = gps_metro['CODIGO_LINHA'].astype(str)\n",
    "\n",
    "# Realize um merge entre os DataFrames usando a coluna 'CODIGO_LINHA' como chave\n",
    "sbe_metro_com_geometria = pd.merge(sbe_metro, gps_metro[['CODIGO_LINHA', 'geometry']], on='CODIGO_LINHA', how='left')\n",
    "\n",
    "# O resultado será um novo DataFrame sbe_metro_com_geometria que incluirá a geometria do gps_metro\n",
    "\n",
    "\n",
    "\n",
    "# # Exibindo o DataFrame resultante\n",
    "sbe_metro_com_geometria.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associando as estações com as localizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbe_estacoes = sbe[sbe['CODIGO_LINHA'].str.startswith(('CM', 'PR', 'SD', 'AC', '1000', '1001', '1002', '2000', '2001', '2002', '3000','3001', '3002', '4001', '4000', '4002', '4003', '4004', '6000', '6001','7000', '7001'))]\n",
    "\n",
    "\n",
    "\n",
    "sbe_estacoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_est_caminho = r\"G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_HEXAGONO\\ESTACAO_ONIBUS V2.xlsx\"\n",
    "sbe_est = pd.read_excel(sbe_est_caminho)\n",
    "sbe_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_estacoes['CODIGO_LINHA'] = sbe_estacoes['CODIGO_LINHA'].astype(str)\n",
    "sbe_est['CODIGO_LINHA'] = sbe_est['CODIGO_LINHA'].astype(str)\n",
    "sbe_est_com_geometria = pd.merge(sbe_estacoes, sbe_est[['CODIGO_LINHA', 'geometry']], on='CODIGO_LINHA', how='left')\n",
    "sbe_est_com_geometria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_est_com_geometria.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_metro_com_geometria.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_unificado = pd.concat([sbe_est_com_geometria, sbe_metro_com_geometria, merged])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convertendo 'DATAHORA_UTILIZACAO' para datetime\n",
    "sbe_unificado['DATAHORA_UTILIZACAO'] = pd.to_datetime(sbe_unificado['DATAHORA_UTILIZACAO'])\n",
    "\n",
    "# Ordenando o DataFrame\n",
    "sbe_sorted = sbe_unificado.sort_values(['CARTAO_USUARIO', 'DATAHORA_UTILIZACAO'])\n",
    "\n",
    "# Calculando a diferença de tempo entre registros consecutivos em minutos\n",
    "sbe_sorted['time_diff'] = sbe_sorted.groupby('CARTAO_USUARIO')['DATAHORA_UTILIZACAO'].diff().dt.total_seconds() / 60\n",
    "\n",
    "# Filtrar validações com intervalos menores que 5 minutos\n",
    "sbe_filtered = sbe_sorted[(sbe_sorted['time_diff'] >= 5) | (sbe_sorted.groupby('CARTAO_USUARIO').cumcount() == 0)]\n",
    "\n",
    "# Selecionar apenas as primeiras validações de cada cartão\n",
    "primeiras_val = sbe_filtered[sbe_filtered.groupby('CARTAO_USUARIO').cumcount() == 0]\n",
    "\n",
    "# Separar as validações com intervalos maiores e menores que 90 minutos\n",
    "val_maiores_90 = sbe_filtered[sbe_filtered['time_diff'] >= 90]\n",
    "val_menores_90 = sbe_filtered[sbe_filtered['time_diff'] < 90]\n",
    "\n",
    "sbe_final = pd.concat([primeiras_val, val_maiores_90, val_menores_90])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbe_final[sbe_final['CARTAO_USUARIO'] == 2310000029300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supondo que merged é o seu DataFrame\n",
    "# Garantir que os dados estão ordenados corretamente\n",
    "sbe_final = sbe_final.sort_values(['CARTAO_USUARIO', 'DATAHORA_UTILIZACAO'])\n",
    "\n",
    "# Deslocando os dados para obter a próxima validação\n",
    "sbe_final['DESTINO_HORARIO'] = sbe_final.groupby('CARTAO_USUARIO')['DATAHORA_UTILIZACAO'].shift(-1)\n",
    "sbe_final['DESTINO_GEOMETRY'] = sbe_final.groupby('CARTAO_USUARIO')['geometry'].shift(-1)\n",
    "\n",
    "# Para a última linha de cada grupo, definir o destino como a primeira origem do grupo\n",
    "for _, group in sbe_final.groupby('CARTAO_USUARIO'):\n",
    "    if len(group) > 1:\n",
    "        last_index = group.index[-1]\n",
    "        first_index = group.index[0]\n",
    "        sbe_final.at[last_index, 'DESTINO_HORARIO'] = group.at[first_index, 'DATAHORA_UTILIZACAO']\n",
    "        sbe_final.at[last_index, 'DESTINO_GEOMETRY'] = group.at[first_index, 'geometry']\n",
    "\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(sbe_final[sbe_final['CARTAO_USUARIO'] == 6850001298748])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando todos os dataframes com as localizações e analisando as diferenças entre 90 minutos de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbe_final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de ajuste dos dados do gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a lista de colunas a serem excluídas\n",
    "colunas_excluir = ['NOME_OPERADORA', 'Unnamed: 7', 'EV', 'DH', 'DESTINO_HORARIO']\n",
    "\n",
    "# Usando a lista para excluir as colunas do DataFrame\n",
    "od = sbe_final.drop(colunas_excluir, axis=1)\n",
    "od.reset_index(drop=True, inplace=True)\n",
    "# Exibindo o DataFrame resultante\n",
    "print(od)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando a coluna 'geometry' para 'ORIGIN_GEOMETRY'\n",
    "od = od.rename(columns={'geometry': 'ORIGIN_GEOMETRY'})\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(od.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od[od[\"CARTAO_USUARIO\"] == 6850001298748])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od['HORA_ORIGEM'] = od['DATAHORA_UTILIZACAO'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od[od[\"CARTAO_USUARIO\"] == 6850001298748])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Supondo que 'od' é o seu DataFrame e 'ORIGIN_GEOMETRY' e 'DESTINO_GEOMETRY' são do tipo Point\n",
    "\n",
    "# Extraindo latitude e longitude para origem e destino\n",
    "od['origin_lat'] = od['ORIGIN_GEOMETRY'].apply(lambda point: point.y if isinstance(point, Point) else None)\n",
    "od['origin_lon'] = od['ORIGIN_GEOMETRY'].apply(lambda point: point.x if isinstance(point, Point) else None)\n",
    "od['destino_lat'] = od['DESTINO_GEOMETRY'].apply(lambda point: point.y if isinstance(point, Point) else None)\n",
    "od['destino_lon'] = od['DESTINO_GEOMETRY'].apply(lambda point: point.x if isinstance(point, Point) else None)\n",
    "\n",
    "# Definindo o nível de resolução do H3, por exemplo, 7\n",
    "resolution = 9\n",
    "\n",
    "# Calculando o índice H3 para origem e destino\n",
    "od['h3_origin'] = od.apply(lambda row: h3.geo_to_h3(row['origin_lat'], row['origin_lon'], resolution) if pd.notnull(row['origin_lat']) and pd.notnull(row['origin_lon']) else None, axis=1)\n",
    "od['h3_destino'] = od.apply(lambda row: h3.geo_to_h3(row['destino_lat'], row['destino_lon'], resolution) if pd.notnull(row['destino_lat']) and pd.notnull(row['destino_lon']) else None, axis=1)\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(od[['ORIGIN_GEOMETRY', 'h3_origin', 'DESTINO_GEOMETRY', 'h3_destino']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_analise_linha = od[(od['h3_origin'].notna()) | (od['h3_destino'].notna())]\n",
    "od_analise_linha = od_analise_linha.groupby('CODIGO_LINHA').size().reset_index(name='Origem e destinos')\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(od_analise_linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_analise_linha_melhor = od[(od['h3_origin'].notna()) & (od['h3_destino'].notna())]\n",
    "od_analise_linha_melhor = od_analise_linha_melhor.groupby('CODIGO_LINHA').size().reset_index(name='Origem e destinos')\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(od_analise_linha_melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_analise_linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od[od['CODIGO_LINHA']== \"67\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od['CARTAO_USUARIO'] = \"ID\" + od[\"CARTAO_USUARIO\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.to_csv(r'g:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_HEXAGONO\\od.csv', sep =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco = r\"G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_ADAPTACAOBOTELHO\\Dezembro_2023\\20231206\\relopemapadecontroleoperacional.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco_analise_linha = pd.read_csv(mco, sep = \";\", encoding= \"latin1\")\n",
    "# Renomeando a coluna 'Código Externo Linha' para 'CODIGO_LINHA'\n",
    "mco_analise_linha = mco_analise_linha.rename(columns={'Código Externo Linha': 'CODIGO_LINHA'})\n",
    "mco_analise_linha.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando e contando\n",
    "od_analise_linha = od[(od['h3_origin'].notna()) | (od['h3_destino'].notna())].groupby('CODIGO_LINHA').size()\n",
    "\n",
    "\n",
    "# Convertendo para DataFrame e renomeando a coluna\n",
    "od_analise_linha = pd.DataFrame(od_analise_linha, columns=['Contagem_ids_OD'])\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(od_analise_linha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando por 'Código Externo Linha' e somando as colunas 'Passageiros' e 'Inteiras'\n",
    "agrupado_soma = mco_analise_linha.groupby('CODIGO_LINHA')[['Passageiros', 'Inteiras']].sum()\n",
    "\n",
    "# Calculando a divisão da coluna 'Inteiras' pela coluna 'Passageiros'\n",
    "agrupado_soma['Proporcao_Inteiras'] = agrupado_soma['Inteiras'].div(agrupado_soma['Passageiros'].replace(0, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(agrupado_soma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o merge entre agrupado_soma e od_analise_linha\n",
    "analise_final = pd.merge(od_analise_linha, agrupado_soma, on='CODIGO_LINHA')\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(analise_final)\n",
    "analise_final.to_excel(r'G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\analise_linha.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o merge entre agrupado_soma e od_analise_linha\n",
    "analise_final_melhorcenario = pd.merge(od_analise_linha_melhor, agrupado_soma, on='CODIGO_LINHA')\n",
    "\n",
    "# Exibindo o DataFrame resultante\n",
    "print(analise_final)\n",
    "analise_final_melhorcenario.to_excel(r\"G:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_HEXAGONO\\geral.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Exemplo de identificador H3\n",
    "h3_index = '89440e4ecb7ffff'\n",
    "\n",
    "# Obter as coordenadas dos vértices do hexágono\n",
    "hex_boundary = h3.h3_to_geo_boundary(h3_index, geo_json=True)\n",
    "\n",
    "# Converter as coordenadas para um formato adequado para folium (latitude, longitude)\n",
    "hex_coords = [[coord[1], coord[0]] for coord in hex_boundary]\n",
    "\n",
    "# Criar um mapa folium centrado no hexágono\n",
    "mapa = folium.Map(location=hex_coords[0], zoom_start=12)\n",
    "\n",
    "# Adicionar o polígono do hexágono ao mapa\n",
    "folium.Polygon(locations=hex_coords, color='blue', fill=True, fill_color='blue').add_to(mapa)\n",
    "\n",
    "# Mostrar o mapa\n",
    "mapa.save(r'g:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\05.3.1.2 OD\\OD_HEXAGONO\\heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hora_especifica = 10\n",
    "df_filtrado = od[od['HORA_ORIGEM'] == hora_especifica]\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "import folium\n",
    "import h3\n",
    "\n",
    "# Contar os destinos baseados em índices H3\n",
    "contagem_destinos = df_filtrado['h3_destino'].value_counts()\n",
    "\n",
    "# Converter a contagem de destinos para um formato adequado para o mapa de calor\n",
    "pontos_mapa_calor = [(h3.h3_to_geo(h)[0], h3.h3_to_geo(h)[1], count) for h, count in contagem_destinos.items()]\n",
    "\n",
    "# Calcular o centro do mapa como a média das localizações dos destinos\n",
    "latitudes = [h3.h3_to_geo(h)[0] for h in contagem_destinos.keys()]\n",
    "longitudes = [h3.h3_to_geo(h)[1] for h in contagem_destinos.keys()]\n",
    "centro_mapa = [sum(latitudes) / len(latitudes), sum(longitudes) / len(longitudes)]\n",
    "\n",
    "# Criar um mapa centrado nesse ponto\n",
    "mapa = folium.Map(location=centro_mapa, zoom_start=12)\n",
    "\n",
    "# Adicionar o mapa de calor ao mapa com um raio menor\n",
    "HeatMap(pontos_mapa_calor, radius=10).add_to(mapa)  # Ajuste o valor de 'radius' conforme necessário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa.save(r'g:\\.shortcut-targets-by-id\\1KlHFtH5Jvo7J9AF_VBixQOXpFsNmZvhD\\05.3. Pesquisa e Ciência dados - GEPDA\\05.3.3 Data Science\\05.3.3.1. Central de dados\\heatmap.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
